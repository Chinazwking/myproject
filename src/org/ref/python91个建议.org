#+STARTUP: INDENT NUM
#+PROPERTY: header-args:python :preamble "# -*- coding: utf-8 -*-" :exports both :results output

* 理解pythonic概念
#+BEGIN_VERSE
所谓的pythonic, 即是看起来充分利用python本身的特性而编写的代码.
比如交换使用a, b = b, a, 遍历使用for i in arr, 打开文件使用with, 这些语法都是别的
语言所不具有的, 编程时要积极使用这些语法.
#+END_VERSE
1. 字符串格式化使用format
2. 包, 模块使用小字母命名且最好短小精悍, 包仅作为命名空间, __init__.py为空

* 编写pythonic代码
#+BEGIN_VERSE
想要编写pythonic的代码, 归根结底还是要全面掌握python特性, 不断学习官方推荐的新的
语法, 阅读设计良好的代码库来加深对python特性的掌握, 才能写出pythonic的代码.
#+END_VERSE
1. 变量命名
   * 避免无意义的单字母
   * 命名最好有意义, 不要产生混淆
   * 不要惧怕长命名
2. 熟练使用工具来检查代码, 比如pylint, pep8等等

* 理解python和c语言的不同之处
#+BEGIN_VERSE
虽然python是用c编写的, 但是很多语法规则上完全不同, 不要用c的思维套用到python上
#+END_VERSE
1. python使用空白缩进
2. python单引号和双引号语义上基本一致
3. python的三元操作符为xx if xx else xx
4. python没有switch, 可以用if else或者字典分发代替

* 在代码中适当添加注释
#+BEGIN_VERSE
合适的代码注释是非常有必要的, 无论是个人回顾还是提供给别人调用, 有效的注释能够节
省大量时间.
#+END_VERSE
1. 注释和代码保持一定距离更加清晰
2. 接口提供详细注释
3. 对复杂代码的思路注释而不是对实现注释
4. 错误的注释还不如没有注释, 所以更新代码时即时更新注释

* 通过适当添加空行使得代码更加优雅
#+BEGIN_VERSE
使用适当的空行分隔不同逻辑可以让代码更加有条理, 更加容易阅读
#+END_VERSE
1. 全局定义之间空两行, 类内方法空一行, 一块代码内的不同逻辑空一行
2. 一行不要超过80(这个应该是针对老式电脑编辑器的约定, 目前现代ide是否要保留感觉有
   待商榷)
3. 不要为了保持对齐而强行加入大量空白
4. 具有紧密关系的代码间不要加空格, 比如a[3], 稀疏关系的加上空格, 比如a == b
5. 空格可以用来强调关系, 比如-5 - 2, 强调是减法而不是负号

* 编写函数的四个原则
#+BEGIN_VERSE
短小精悍, 设计合理, 向下兼容, 职责明确
#+END_VERSE
1. 函数尽量短小, 循环嵌套不超过3层
2. 函数接口合理易用, 参数不宜过多
3. 设计时考虑向下兼容
4. 一个函数只做一件事, 保持同一级函数的抽象层次一致性

* 将常量集中到一个文件
#+BEGIN_VERSE
将常量定义到一个文件之中, 便于查看和维护
#+END_VERSE
两种实现方式:
   * 直接大写MAX_VALUE, 约定用法
   * 定义一个模块:
     #+BEGIN_SRC python
       class _Const:
           class ConstError(TypeError): pass
           class ConstCaseError(ConstError): pass
           def __setattr__(self, name, value):
               if self.__dict__.has_key(name):
                   raise self.ConstError, "Can't change const.%s".format(name)
               if not name.isupper():
                   raise self.ConstCaseError, "%s is not uppercase".format(name)
               self.__dict__[name] = value

       import sys
       sys.modules[__name__] = _Const()

       import const
       const.MY_CONSTANT = 1
     #+END_SRC
     使用这种方式定义可以确保变量值不变并且一定是大写

* 利用assert语句发现问题
#+BEGIN_VERSE
断言是用来捕获约束而不是捕获错误的
具体来说, 断言是用来处理程序继续执行逻辑上前提条件, 而不是具体捕获异常
#+END_VERSE
1. 不要滥用, 影响性能
2. python自身能处理就不要用断言
3. 不要用来检查用户输入
4. 可以用来检测函数返回值是否合理

* 数据交换值不推荐使用中间变量
#+BEGIN_VERSE
pythonic的交换方式是a, b = b, a
比传统的中间变量交换法更优雅且更高效
#+END_VERSE

* 充分利用lazy evaluation的特性
#+BEGIN_VERSE
利用延时计算可以节省空间, 提升性能
#+END_VERSE
1. 利用and, or的求值短路特性节省时间
2. 利用生成器节省空间

* 理解枚举替代实现的缺陷
#+BEGIN_VERSE
python3.4之前模拟的枚举存在很多缺陷, 3.4支持Enum
#+END_VERSE
1. 替代枚举可以重复赋值
2. 可以进行无意义的操作

* 不推荐使用type进行类型检查
#+BEGIN_VERSE
python的理念就是通过自动类型检查并根据需要隐式转换, 如果不行则抛出异常, 所以一般
不会主动进行类型检查
#+END_VERSE
1. type无法识别继承自内建类的类型
2. type无法识别古典类之间的区别
3. 一定要检查使用isinstance

* 尽量转换为浮点型后再做除法
#+BEGIN_VERSE
python2.7 两个整形之间默认的除法是整形除法, 会截断小数, 所以两个整数相除截断这个
效果是你想要的, 否则手动转为浮点型
#+END_VERSE
1. 可以再python2.7中使用from __future__ import division来使得默认使用浮点除法
2. 浮点数不要使用==比较, 使用a-b<=decision来指定精度进行比较

* 警惕eval()的安全漏洞
#+BEGIN_VERSE
"eval is evil"
#+END_VERSE
1. 用户可能通过eval执行破坏性代码, 所以eval不能出现在用户可能会调用的位置上
2. eval导致代码调试困难
3. 一定要暴露给用户可以使用ast.literal_eval

* 使用enumerate()获取序列迭代的索引和值
#+BEGIN_VERSE
enumerate可以优雅的处理同时获取索引和迭代值的问题, 更棒的一点是他是惰性的.
#+END_VERSE
1. 对字典使用获取的是索引和key二元组, 这个要注意

* 分清==和is的使用场景
#+BEGIN_VERSE
is判断是不是一个对象, 而==判断是不是一个值
#+END_VERSE
1. 是否为同一个对象可以理解为是不是在内存中指向同一个区域
2. == 实际上调用的是__eq__魔术方法

* 考虑兼容性, 尽可能使用Unicode
#+BEGIN_VERSE
通过统一使用unicode, 可以解决让人头疼的乱码问题
#+END_VERSE
1. 使用from __future__ import unicode_literals 可以让所有的字面量变为unicode

* 构建合理的包层次来管理module
#+BEGIN_VERSE
python中的包是用来管理组织代码结构的工具, 通过一层层目录结构, 可以使得避免不同路
径下的两个同名模块发生冲突, 并且可以根据模块的功能将其放到不同的包中, 使得代码结
构更加清晰.
#+END_VERSE
1. 通过合理的使用包, 可以让代码:
   * 便于维护和使用
   * 最大程度避免命名冲突

* 有节制的使用from ... import语法
#+BEGIN_VERSE
from import 语法虽然在有些时候减少代码量, 但是很容易导致命名冲突, 循环导入问题,
而且也不方便在运行时打猴子补丁
#+END_VERSE
1. from xx import *, 最好别用
2. from xx import ABC, 导入属性少用, 导入模块可以用
3. import xxx, 除了导致代码变长, 用起来麻烦, 其他都是优点

* 优先使用绝对导入
#+BEGIN_VERSE
绝对不要使用隐式相对导入, 有节制的使用相对导入, 最好使用绝对导入.
#+END_VERSE
1. from __future__ import absolute_import可以禁止隐式相对导入
2. 相对导入在作为顶级模块执行时会丢失自己的层次信息, 导致相对导入失效

* i+=1 不等于 ++i
#+BEGIN_VERSE
python不支持自增, ++i在python等效于+(+i), 所以这句话约等于无事发生
#+END_VERSE

* 使用with自动关闭资源
#+BEGIN_VERSE
with语句是更加优雅简单的资源管理方法, 通过with管理资源可以替代老式的
try/catch/finally式写法
本质上支持with语法的对象实现了__enter__和__exit__两个接口用来控制
资源状态
#+END_VERSE
1. 推荐使用contextlib中的contextmanager装饰器来实现自己的上下文管理器
   形式大概类似于:
   #+BEGIN_SRC python
     @contextmanager
     def mycontext():
         print('__enter__')
         # 为了确保yield的对象抛出异常能够正确__exit__, 最好还是使用try, finally
         try:
             yield 0  # yield之前为__enter__, 之后为__exit__, 返回的值会赋值给as的对象
         finally:
             print('__exit__')
   #+END_SRC
   
* 使用else字句简化循环
#+BEGIN_VERSE
else在循环中, 非break时调用, else在异常中, 没有发生异常时调用. 合理的使用else
可以减少状态变量的使用
#+END_VERSE

* 遵循异常处理的几点基本原则
#+BEGIN_VERSE
精准, 高粒度的使用异常, 注意异常捕获顺序, 正确处理异常重抛出
#+END_VERSE
1. 不要except所有异常
2. try包含的语句越少越好
3. except的异常越具体越好
4. 越在继承链底部的异常, 越应该将他放到多个except语句的前面, 以便精准捕获
5. 异常抛出的信息最好对开发, 用户更加友好

* 避免finally中可能发生的陷阱
#+BEGIN_VERSE
finally不是银弹, 并不能解决一切由异常导致的问题
#+END_VERSE
1. 如果finally里又出现了新的异常或者直接返回, 旧的异常会丢失
2. finally如果存在返回, 会截断正常的返回, 所以一般不在finally返回

* 深入理解None, 正确判断对象是否为空
#+BEGIN_VERSE
None不是空, 当一个值和None比较时, 当且仅当值也为None时他们才相等, 其他情况一律不
等
#+END_VERSE
1. python会根据对象的__nonzero__和__len__判断对象是否为空, 如果没实现这两个接口则
   默认为不空

* 连接字符串优先使用join而不是+
#+BEGIN_VERSE
在处理大规模字符串连接时, join的效率远远高于+, 所以使用join连接字符
#+END_VERSE
1. join一次性计算需要的内存, 然后将内容复制到新的字符串中
2. 每+一次都在内存中复制字符串一遍, 所以大数量时效率低

* 格式化字符串尽量使用format而不是%
#+BEGIN_VERSE
不要使用%格式化, 一律使用format
#+END_VERSE
1. 功能更强大, 更灵活, 更方便
2. %最终会被format替代

* 区别对待可变对象和不可变对象
#+BEGIN_VERSE
不可变对象的值无法改变, 而可变对象的值可以改变. 有些时候你以为不可变对象的值变了,
实际上并不是值变了, 而是给你的标识符分配了新的对象
#+END_VERSE
1. 函数默认参数绝对不要使用可变参数, 所有对函数的调用, 他们的默认参数都指向同一个
   对象

* [], (), {}: 一致的容器初始化形式
#+BEGIN_VERSE
python默认的几种可迭代类型都支持列表解析初始化形式, 如果初始化逻辑不是特别复杂且
占用空间不大推荐使用, 更清晰且效率更高
#+END_VERSE
1. 列表[i**j for i in range(10) for j in range(10) if i > 5 and j > 5]
2. 字典{i: 0 for i in range(10)}
3. 集合{i for i in range(10)}
4. 元组(i for i in range(10))
5. 函数如果支持可变参数列表, 也可用列表解析func(i for i in range(10))

* 记住函数传参既不是传值也不是传引用
#+BEGIN_VERSE
python的传参是传对象的引用, 不是传值也不是传引用
#+END_VERSE
1. 对于任何形参, 在内部给形参赋值都相当于给引用指向了一个新的内存, 不会修改实参
2. 对于可变类型形参, 如果只是修改形参的值, 那么由于和实参引用的是同一个内存, 也会
   影响到实参的值

* 警惕默认参数的潜在问题
#+BEGIN_VERSE
默认参数不要使用可变对象, 除非你清楚的知道这样做的后果是你想要的
#+END_VERSE
1. 如果默认参数是可变对象, 函数内每次对可变参数的修改都会影响下一次调用, 因为可变
   参数只会初始化一次, 后面的所有调用用的都是同一个可变参数
2. 如果你就是想要参数动态变化的效果, 比如说默认参数是当前时间, 那么可以让参数为:
   #+BEGIN_SRC python :session :results value
     import time
     def get_time(time=time.time):
         return time()
     get_time()
   #+END_SRC

   #+RESULTS:
   : 1625794781.86

* 慎用变长参数
#+BEGIN_VERSE
变长参数会导致接口定义非常不明确, 想要调用接口要求必须对变长参数含义有精确的理解,
脱离了接口简单易用的本意, 所以谨慎使用
#+END_VERSE
1. 使用变长参数时, 考虑此函数是否功能过多, 是否需要重构
2. 如果仅仅只是想要传字典或者列表, 不要用可变参数
3. 在参数数目不定, 实现函数多态和装饰器, 或子类调用父类方法时可以使用可变参数

* 深入理解str()和repr()的区别
#+BEGIN_VERSE
str面向用户, repr面向解释器
#+END_VERSE
1. 当str没实现时会调用repr, 所以一般要实现repr
2. 一般情况下来说有如下等式, obj == eval(repr(obj))
3. print调用的是str, 交互环境里直接输入变量调用的是repr

* 分清staticmethod和classmethod的适用场景
#+BEGIN_VERSE
静态方法是放置于类内的普通函数, 功能和放到类外的函数是一致的, 出于代码紧凑和组织
原因才放到类内部, 而类方法一般用于和类本身属性有关的情况, 比如说修改类属性, 类工
厂函数等等
#+END_VERSE
1. 静态方法在语义上和类没有任何关系
2. 类方法可以动态根据调用类方法的类来修改类本身属性

* 掌握字符串的基本用法
#+BEGIN_VERSE
字符串有很多很方便的接口, 需要仔细阅读阅读一下文档, 对接口大概心里有数
#+END_VERSE
1. 判断对象是否为字符串使用isinstance(obj, basestring)
2. split('')和split()的结果是不一样的, 后者会认为所有的连续的空字符为一个间隔
3. 字符串自带很多控制格式的接口, 可以更加准确的控制排版

* 按需选择sort()和sorted()
#+BEGIN_VERSE
如果想要节省空间且自身是list则使用sort原地排序, 否则一般使用sorted进行排序, 它支
持序列类型, 且不修改原对象
#+END_VERSE
1. 都支持key参数, reverse参数, 可以灵活的控制排序规则和结果
2. cmp参数尽量少用, 因为效率要低于key参数

* 适用copy模块深拷贝对象
#+BEGIN_VERSE
如果想要拷贝出一个完全独立的对象, 使用copy.deepcopy
#+END_VERSE
1. 浅拷贝是指仅复制最外层, 如果内层还有引用则复制出来的新对象和原对象内层指的还是
   同一个单位
2. 深拷贝是指遇到引用会递归拷贝其所指向的内容, 直到最底层, 所以可以复制出一个和原
   对象完全没关系的新对象

* 适用Counter进行计数统计
#+BEGIN_VERSE
如果有统计序列中元素数目的需求, 请使用collections.Counter
#+END_VERSE
1. 支持+, -, |, &等集合操作
2. 使用elements获得所有元素, 使用most_common获得数量最多的元素及其次数
3. 使用update, subtract来改变各个元素的数目

* 深入掌握ConfigParser
#+BEGIN_VERSE
ConfigParser可以用来读取ini文件格式的配置信息
#+END_VERSE
1. getboolean()可以将0, no, false, off都转为False, 1, yes, true, on转为True, 其
   他抛出异常
2. 当在指定的节[section]找不到配置项时, 回去[DEFAULT]节中去寻找
3. 配置项支持参数替换, 比如coon_str = %(user)s:%(pw)s, 如果查找的节内有user和pw的
   定义, 则会自动替换占位符

* 适用argparse处理命令行参数
#+BEGIN_VERSE
python提供了argparse用来优雅的处理命令行参数, 需要的时候记得使用
#+END_VERSE
- 示例:
  #+BEGIN_SRC python
    import argparse

    parser = argparse.ArgumentParser(description='argsparse example')
    # 支持参数分组
    pos = parser.add_argument_group('positional', 'positional argument example')
    # default代表默认参数, choices代表取值范围, help代表描述
    pos.add_argument('str', type=str, choices=['a', 'b'], help='word')
    # type代表期望输入的类型, list是参数名， nargs代表至少输入一个参数(可以接受多个)
    pos.add_argument('list', type=int, nargs='+',
                    help='positional arguments example')
    opt = parser.add_argument_group('optional', 'optional argument example')
    # --开始代表需要参数的参数, default为默认值
    opt.add_argument('--name', type=str, default='dog', help='name')
    # required代表必须输入, '-a'为'--age'简写
    opt.add_argument('-a', '--age', type=int, required=True, help='age')
    # 不带参数的可选参数, 一般当作开关, dest代表存储名称, action代表默认操作
    opt.add_argument('-v', dest='verbose', action='store_true', help='verbose')
    # 子命令sub
    subparser = parser.add_subparsers(help='sub-command help')
    parser_sub = subparser.add_parser('sub', help='sub help')
    parser_sub.add_argument('--test', type=bool, help='is test')
    parser_sub.add_argument('bool', type=str, help='bool')

    parser.print_help()
    # args = parser.parse_args()
  #+END_SRC

  #+RESULTS:
  #+begin_example
  usage: [-h] [--name NAME] -a AGE [-v] {a,b} list [list ...] {sub} ...

  argsparse example

  positional arguments:
    {sub}              sub-command help
      sub              sub help

  optional arguments:
    -h, --help         show this help message and exit

  positional:
    positional argument example

    {a,b}              word
    list               positional arguments example

  optional:
    optional argument example

    --name NAME        name
    -a AGE, --age AGE  age
    -v                 verbose
  #+end_example

- 使用ArgumentParser实例方法exit和error来处理异常情况

* 适用pandas处理大型CSV文件
#+BEGIN_VERSE
csv文件是指(Comma Seperated Values)文件, 一般是以,分隔的文件, excel就属于此类
python提供了库csv用来处理这种文件类型
#+END_VERSE
- 示例:
  #+BEGIN_SRC python
    import csv
    """假设test.csv中内容为
    name, A, B, C, D
    a, 1, 2, 3, 4
    b, 5, 6, 7, 8
    """
    with open('D:\\hello\\test.csv', 'r+') as fp:
        result = []
        print('==reader==')
        for row in csv.reader(fp):
            result.append(row)
            print(row)
        fp.seek(0)
        # delimiter代表写入时使用的分隔符, 默认是,
        writer = csv.writer(fp, delimiter=':')
        # DictWriter用法和此类似
        for row in result:
            writer.writerow(row)
        fp.seek(0)
        print('==DictReader==')
        for row in csv.DictReader(fp, delimiter=':'):
            print(row)
  #+END_SRC

  #+RESULTS:
  : ==reader==
  : ['name: A: B: C: D']
  : ['a: 1: 2: 3: 4']
  : ['b: 5: 6: 7: 8']
  : ==DictReader==
  : {'name: A: B: C: D': 'a: 1: 2: 3: 4'}
  : {'name: A: B: C: D': 'b: 5: 6: 7: 8'}

- 如果碰到上百M的大文件, 使用pandas来进行处理是比较好的选择

* 一般情况适用ElementTree解析XML
#+BEGIN_VERSE
处理xml文件时, 请使用ElementTree模块来处理
#+END_VERSE
1. 使用简单, 将整个xml作为树, 每一个元素的属性以字典表示
2. 内存消耗低
3. 支持XPath, 非常方便获取任意节点的值
- 示例:
  #+BEGIN_SRC python :results value
    try:
        # 优先加载cElementTree, 性能更好
        import xml.etree.cElementTree as ET
    except ImportError:
        import xml.etree.ElementTree as ET

    """假设text.xml文件内容为:
    <test>
        <name author='wzw' age='10'>
            <purpose>test</purpose>
        </name>
    </test>
    """

    tree = ET.parse("D:\\hello\\test.xml")
    root = tree.getroot()
    result = []
    result.append('root tag={}'.format(root.tag))  # 打印根元素的tag
    # 遍历xml文档的第二层
    for child in root:
        # 第二层节点的标签名称和属性
        result.append('tag={} attrib={}'.format(child.tag, child.attrib))
        for children in child:
            # 第三层节点的标签名称和属性
            result.append('tag={}, value={}'.format(children.tag, children.text))
    # 如果不想一层层遍历, 直接使用find等接口可以直接定位到准确层级, 比如find('name/purpose').text == 'test'
    return '\n'.join(result)
  #+END_SRC

  #+RESULTS:
  : root tag=test
  : tag=name attrib={'age': '10', 'author': 'wzw'}
  : tag=purpose, value=test

* 理解模块pickle优劣
#+BEGIN_VERSE
pickle是python提供的一种通用的序列化/反序列化接口, 基本支持大部分python类型, 包括
类, 函数这些比较刁钻的类型
#+END_VERSE
- 优点:
  1. 接口简单易用, 使用load和dump (由于序列化出来的东西不像json一样可读, 所以带s
     两个接口不常用)
  2. 存储格式在不同平台的python之间通用
  3. 支持广泛的数据类型
  4. 模块支持扩展来处理自定义的类型
  5. 能够自动维护对象间的引用
- 缺点:
  1. 不能保证操作的原子性
  2. 存在安全性问题, 可以通过loads执行破坏性代码
  3. python特定格式, 不同语言之间无法解析
- 示例:
  #+BEGIN_SRC python :session :results pp
    import pickle
    def test():
        return 'hello world'
    print(pickle.loads(pickle.dumps(test))())
  #+END_SRC

  #+RESULTS:
  : hello world

* 序列化的另一个不错的选择
#+BEGIN_VERSE
python自带对json的完全支持, 对序列化性能要求不是特别高的情况优先使用.
主要用4个接口, load, loads, dump, dumps, 不带s的操作文件, 带s操作字符串
#+END_VERSE
1. 简单易用, 支持多种数据类型(null, str, int, float, bool, list, dict)
2. 存储可读性更好
3. 支持跨平台操作
4. 可以扩展来支持json本身不支持的类型
5. 示例:
   #+BEGIN_SRC python
     import json
     obj = {'a': {'b': [1, 2, 3], 'c': True}, 'b': 'help', 'c': 1.5}
     sResult = json.dumps(obj)  # sResult is str
     new_obj = json.loads(sResult)
     print new_obj == obj
   #+END_SRC

   #+RESULTS:
   : True
   
* 适用traceback获取栈信息
#+BEGIN_VERSE
当程序捕获了特定异常并打印错误时, 经常会丢失掉traceback信息, 通过traceback模块可
以打印出追踪信息
#+END_VERSE
1. inspect模块, sys.exc_info(), 也都提供了对异常跟踪信息的获取方法
- 示例:
  #+begin_src python
    import traceback
    def f():
        g()
    def g():
        k()
    def k():
        raise RuntimeError('Runtime test')

    try:
        f()
    except RuntimeError as e:
        print traceback.format_exc()  # 这里捕获了异常, 并生成了跟踪信息字符串
  #+end_src

  #+RESULTS:
  : Traceback (most recent call last):
  :   File "<stdin>", line 11, in <module>
  :   File "<stdin>", line 4, in f
  :   File "<stdin>", line 6, in g
  :   File "<stdin>", line 8, in k
  : RuntimeError: Runtime test
  : 

* 适用logging记录日志信息
#+BEGIN_VERSE
python提供了logging模块来处理日志信息, 提供了级别控制, 输出格式, 输出定向, 日志过
滤等多种强大功能, 并且保证了线程安全, 非常强大.
#+END_VERSE
1. 尽量为logging去一个名字, 比如模块名, ~logger = logging.getLogger(__name__)~
2. logging是线程安全但不保证进程安全, 所以多进程请使用不同的日志文件
示例:
#+begin_src python
  import logging
  import sys
  sys.stderr = sys.stdout
  logging.basicConfig(level=logging.INFO,
                      format='%(asctime)s %(levelname)s %(message)s',)
  logger = logging.getLogger(__name__)
  logger.debug('this is a debug')  # 由于级别设置为info, debug不会显示
  logger.info('this is a info')
  logger.critical('this is a critical')
#+end_src

#+RESULTS:
: 2021-07-08 15:49:26,249 INFO this is a info
: 2021-07-08 15:49:26,249 CRITICAL this is a critical

* 适用threading编写多线程程序
#+BEGIN_VERSE
threading提供了丰富的特性来操控线程, 而thread模块是以低级原始的方式控制线程, 所以
编写多线程程序时优先使用threading模块
#+END_VERSE
1. threading支持各种锁, 信号量, 条件变量, 事件来控制同步和互斥
2. threading可以join来等待线程执行结束
3. threading支持守护线程, 支持等待所有子线程结束后主线程才退出的功能
4. python3已经没有thread模块了, 表明了语言开发者的态度
示例:
#+begin_src python
  import threading
  import time
  def func(s, delay):
      time.sleep(delay)
      print(s)

  t1 = threading.Thread(target=func, args=('a', 1))
  t2 = threading.Thread(target=func, args=('a', 2))
  t2.setDaemon(True)
  print('t1 is daemon? {}'.format(t1.isDaemon()))
  print('t2 is daemon? {}'.format(t2.isDaemon()))
  print('=== after 1 second ===')
  t1.start()
  t2.start()  # 由于t2线程设置了守护进程, 所以当线程1结束时程序会直接退出, 不会输出线程2的结果
#+end_src

#+RESULTS:
: t1 is daemon? False
: t2 is daemon? True
: === after 1 second ===
: a

* 适用Queue使多线程编程更安全
#+BEGIN_VERSE
python提供了三种线程同步队列, 这三种队列都保证线程安全, 使用这三个队列传递数据时
不需要做任何同步互斥措施
#+END_VERSE
1. 提供的三种队列为:
   - Queue.Queue(maxsize), 先进先出队列
   - Queue.LifoQueue(maxsize), 先进后出栈
   - Queue.PriorityQueue(maxsize), 优先队列
2. 示例:
    #+begin_src python
      import Queue
      import threading
      import time

      class Producer(threading.Thread):
          def __init__(self, queue, name):
              super(Producer, self).__init__()
              self.queue = queue  # 队列
              self.name = name

          def run(self):
              print '{} {} start!'.format(self.__class__.__name__, self.name)
              count = 5
              while count:
                  self.queue.put('{}({})'.format(self.name, count), True)
                  count -= 1
              self.queue.task_done()
              print '{} {} done!'.format(self.__class__.__name__, self.name)

      class Consumer(threading.Thread):
          def __init__(self, queue, name):
              super(Consumer, self).__init__()
              self.queue = queue  # 队列
              self.name = name

          def run(self):
              print '{} {} start!'.format(self.__class__.__name__, self.name)
              result = []
              while True:
                  val = self.queue.get(True, 1)
                  result.append(val)
                  time.sleep(1)
                  if self.queue.empty():
                      break
              print('{} result = {}'.format(self.name, result))

      queue = Queue.Queue(3)
      producer1 = Producer(queue, '1')
      producer2 = Producer(queue, '2')
      consumer1 = Consumer(queue, '1')
      consumer2 = Consumer(queue, '2')
      producer1.start()
      producer2.start()
      consumer1.start()
      consumer2.start()
    #+end_src

    #+RESULTS:
    : Producer 1 start!
    : Producer 2 start!
    : Consumer 1 start!
    : Consumer 2 start!
    : Producer 1 done!
    : Producer 2 done!
    : 1 result = ['1(5)', '1(3)', '1(1)', '2(3)', '2(2)']
    : 2 result = ['1(4)', '1(2)', '2(5)', '2(4)', '2(1)']

* 利用模块实现单例模式
#+BEGIN_VERSE
由于python本身的灵活性, 导致传统的单例实现模式在python中总是有着各种各样的瑕疵,
但实际上python模块本身就是完备的单例
#+END_VERSE
1. 模块只初始化一次
2. 模块的变量全部绑定到模块上
3. import是线程安全的
4. 如果扩展一下单例的定义, 并不需要全局唯一, 只需要所有实例的状态一致即可

* 用mixin模式让程序更加灵活
#+BEGIN_VERSE
混入实际上是python中多重继承的一种使用方式, mixin类可以理解为带有实现的接口, 一般
实现了某种单一功能, 宿主类为了获得这种功能从而混入(mixin)这个类, 获得了这个功能,
使用混入避免多重继承的坏处, 最大限度的获得了代码重用的好处.
#+END_VERSE
1. 一般混入类要符合以下的要求:
   - 单一职责
   - 混入类对宿主类一无所知(但是可能要求宿主必须实现了某些接口, 有某些属性才能混入)
   - 宿主类的原本功能不会因为去掉混入类而受到影响, 混入类本身也不存在super等调用
     以免陷入mro的陷阱
   - 混入类不会继承一般类, 也不能实例化
2. python支持静态混入(定义时多重继承), 动态混入修改__bases__在python2.7.13是无法
   实现的
- 示例:
  #+begin_src python
    class Gun(object):
        def __init__(self):
            self.magazine = 2
            self.left_bullet = 1

        def fire(self):
            if self.left_bullet > 0:
                self.left_bullet -= 1
                print 'biu', 

        def reload(self):
            print('装弹')
            self.left_bullet = self.magazine

        def empty(self):
            return self.left_bullet == 0

    class AiMinix(object):
        def autofire(self, count):
            for i in range(count):
                if self.empty():
                    self.reload()
                self.fire()

    class KnifeMinix(object):
        def stab(self):
            print('刺刀攻击')

    # 这个武器依旧是一把枪, 而不是Ai控制或者是刺刀, 他只是混入了这两种功能
    class BigFuckingGun(Gun, AiMinix, KnifeMinix):
        pass

    bfg = BigFuckingGun()
    bfg.fire()
    bfg.autofire(6)
    bfg.stab()
  #+end_src

  #+RESULTS:
  : biu 装弹
  : biu biu 装弹
  : biu biu 装弹
  : biu biu 刺刀攻击

* 用发布订阅模式实现松耦合
#+BEGIN_VERSE
发布订阅模式是传统观察者模式的超集, 通过将发布和订阅者的松耦合集中到中介者身上,
发布者和订阅者实现了完全的解耦
#+END_VERSE
1. 发布者和订阅者对对方毫不知情, 发布者通过中介投递消息, 订阅者通过中介得到消息
2. message的消息订阅是全局的, 所以起名要注意不要发生冲突, 可以通过uuid来生成唯一
   名称
- 示例:
  #+NAME: 订阅/发布
  #+begin_src python :result output
    import message  # pip install message

    SUBJECT = 'subject'  # 订阅的主题

    def subscriber_1():
        print('s1 receive subject')
        ctx = message.Context()
        ctx.discontinued = True
        print('swallow message')
        return ctx  # 通过返回上下文信息中断消息传递

    def subscriber_2():
        print('s2 receive subject')

    def subscriber_3():
        print('s3 receive subject')

    message.sub(SUBJECT, subscriber_1)  # 订阅
    message.sub(SUBJECT, subscriber_2)
    message.sub(SUBJECT, subscriber_3, front=True)  # 通过front参数使得3第一个收到消息
    message.pub(SUBJECT)  # 发布
  #+end_src

  #+RESULTS: 订阅/发布
  : s3 receive subject
  : s1 receive subject
  : swallow message

  #+NAME: 观察者模式
  #+begin_src python :result output
    import message

    def greet(people):  # 观察者
        print 'hello {}'.format(people.name)

    @message.observable  # 注册为被观察对象
    class Foo(object):
        def __init__(self, name):
            self.name = name

        def pub_greet(self):
            print('notify')
            self.pub('greet', self)

    foo = Foo('kesa')
    foo.sub('greet', greet)  # 注册成为观察者
    foo.pub_greet()  # notify
  #+end_src

  #+RESULTS: 观察者模式
  : notify
  : hello kesa

* 用状态模式美化代码
#+BEGIN_VERSE
当一个类有很多不同的状态, 每个状态各自的操作, 这个时候可以使用状态模式来简化代码
#+END_VERSE
1. 状态模式通过将方法分派的不同的状态类中有效避免了大量ifelse语句
2. 每个状态拥有自己独有的方法, 当在状态上调用错误的方法时可以迅速发现错误的原因
3. 参考[[file:游戏编程模式.org::*状态模式][状态模式]]
4. 示例:
   #+begin_src python
     import state  # pip install state

     class StateBase(state.State):
         """自定义状态基类, 用于实现默认的进入和离开行为
         """
         @state.behavior
         def __begin__(host):  # 每次进入状态时会调用此接口, 初始化
             pass

         @state.behavior
         def __end__(host):  # 每次离开状态时会调用此接口, 清理
             print '{} ->'.format(host.herostate.__name__),


     @state.stateful  # stateful用于将类状态化
     class Hero(object):
         """英雄类

         可以做出各种各样的操作
         """
         @property
         def herostate(self):
             return state.curr(self)  # curr用于查看当前状态

         class Stand(StateBase):
             """站立状态
             """
             default = True  # 英雄单位默认处在站立状态, 必须有一个状态类有此属性
             @state.behavior  # 实际上是staticmethod的别名, 状态保存在self里, 自身只有行为, 因此是静态的
             def jump(host):  # 这个host代表的是宿主Hero类的实例,  不是自身
                 state.switch(host, Hero.Jump)  # switch用于状态转换

             @state.behavior
             def dash(host):
                 state.switch(host, Hero.Dash)

         class Jump(StateBase):
             """跳跃状态
             """
             @state.behavior
             def smash_down(host):
                 print('英雄砸地板')
                 host.stand()

             @state.behavior
             def stand(host):
                 state.switch(host, Hero.Stand)

         class Dash(StateBase):
             """冲刺状态
             """
             @state.behavior
             def stand(host):
                 state.switch(host, Hero.Stand)

     print '状态变化:',
     hero = Hero()
     hero.jump()
     hero.stand()
     hero.dash()
     hero.stand()
     print(hero.herostate.__name__)
     try:
         hero.smash_down()
     except AttributeError as e:
         print('无法在{}时砸地板'.format(hero.herostate.__name__))
   #+end_src

   #+RESULTS:
   : 状态变化: Stand -> Jump -> Stand -> Dash -> Stand
   : 无法在Stand时砸地板

* 理解build-in objects
#+BEGIN_VERSE
python之中, 一切皆是对象
#+END_VERSE
1. object和古典类没有基类, type的基类是object
2. object是type的实例, type实际上是元类, 即类的模板
3. object和所有内建类型以及衍生的用户类都是type的实例
4. 所有用户定义古典类类型都为instance, 元类为types.ClassType
5. 不能仅通过继承关系来判断一个类是不是古典类, 它元类是不是types.ClassType才是
   关键, 即type(cls) == types.ClassType
6. 一定使用新式类(继承object), py3已经移除了古典类

* __init__()不是构造方法
#+BEGIN_VERSE
python中__new__才是传统意义上的构造方法, __init__是用来在类实例构造好之后用来初始
化变量的
#+END_VERSE
1. __new__是类方法, __init__是实例方法
2. __new__创建的实例会自动传给__init__进行初始化, 如果__new__返回的实例的类型不
   是自身的类型则不会调用__init__
3. __new__和__init__的参数必须一致
4. 一般来说不需要实现__new__, 除了以下几种情况:
   - 继承内建不可变类型, 由于__init__是无效的, 必须实现__new__
   - 工厂函数, 单例模式, 或者元编程

* 理解名字查找机制
#+BEGIN_VERSE
python查找名字定义时, 按照LEGB顺序查找, 即(local->enclosing->global->builtin)
#+END_VERSE
1. 作用域含义说明:
   - 局部作用域(local) :: 函数的每次调用都会创建一个局部作用域, 函数内部的任意
     赋值操作(=, import, def等等)都会在局部创建新的变量, 并且尽在局部作用域可见
   - 嵌套作用域(enclosing) :: 函数内部定义函数, 相对于内层函数, 外边的这层函数定
     义的变量处在嵌套作用域. 当内部函数如果引用了嵌套作用域的变量, 这个叫做闭包
   - 全局作用域(global) :: 定义在单个文件最顶层的变量所处的作用域, 此作用域中所有
     变量名此文件可见
   - 内建作用域(built-in) :: 在标准库模块__builtin__模块内查找
2. 函数内部想要修改全局作用域变量必须使用global关键字, 想要修改嵌套作用域变量在
   py3可以使用nonlocal关键字, py2无法修改, 只会在局部作用域创建新的变量
   
* 为什么需要self参数
#+BEGIN_VERSE
保留self仅会让你在定义的时候多写几个字符, 但却可以让一系列python的动态特性能够
正常运作
#+END_VERSE
1. self的起因是python的设计者创造语言时收到了其他语言的影响
2. 语言本身的动态性使得使用self能带来便利, 比如子类覆盖了父类的函数, 但可以通过
   base.methodname(self, arguments)来调用父类的接口
3. 存在同名局部或者全局变量时, 有self更容易区分哪个是实例属性

* 理解MRO与多重继承
#+BEGIN_VERSE
当使用多重继承时, 如果不同父类存在相同的属性, 此时使用MRO(方法解析顺序)来决定使用
哪一个父类的属性
#+END_VERSE
1. 通过访问类的__mro__属性获得方法和属性查找顺序, 越靠前越先被找到, 找到即停止
2. 古典类使用自顶向下, 自左至右的深度优先遍历方法来决定__mro__(顶是指子类)
3. 新式类使用C3算法来决定__mro__:
   #+begin_quote
   我们把类 C 的线性化(MRO)记为 L[C] = [C1, C2,…,CN].其中 C1 称为 L[C] 的头,
   其余元素 [C2,…,CN] 称为尾. 如果一个类 C 继承自基类 B1, B2, ..., BN，那么我们
   可以根据以下两步计算出 L[C]:
   L[object] = [object]
   L[C(B1…BN)] = [C] + merge(L[B1]…L[BN], [B1]…[BN])
   
   这里的关键在于 merge，其输入是一组列表，按照如下方式输出一个列表:

     1. 检查第一个列表的头元素(如 L[B1] 的头),记作 H
     2. 若H未出现在其它列表的尾部, 则将其输出, 并将其从所有列表中删除, 然后回到
        步骤1; 否则, 取出下一个列表的头部记作 H, 继续该步骤
     重复上述步骤, 直至列表为空或者不能再找出可以输出的元素. 如果是前一种情况,
     则算法结束; 如果是后一种情况, 说明无法构建继承关系, Python会抛出异常.
   #+end_quote
   假设存在继承关系:
   #+begin_example
   class X(object), class Y(object), class A(X, Y)
   那么使用C3算法得到如下__mro__:
     L[object] = [object]
     L[X] = X + merge(L[object], object) = [X, object]
     L[Y] = Y + merge(L[object], object) = [Y, object]

     L[A] = A + merge(L[X], L[Y], X, Y)
          = A + X + merge(object, L[Y], Y)
          = A + X + Y + merge(object, object)
          = [A, X, Y, object]
   #+end_example

* 理解描述符机制
#+BEGIN_VERSE
通过.来访问实例属性和通过__dict__来访问实例属性是一样的, 但是对于类属性来说,
.封装了查找的细节. 使用.来访问类的描述符属性会调用描述符的__get__, 类的方法
就是描述符
#+END_VERSE
1. 通过实例.访问描述符会被转换为type(obj).__dict__['x'].__get__(obj, type(obj))
2. 通过类.访问描述符会被转换为cls.__dict__['x'].__get__(None, cls)
3. 函数, classmethod, staticmethod, property等实现都用到了描述符

* 区别__getattr__()和__getattribute__()方法
#+BEGIN_VERSE
__getattribute__在对所有的实例属性访问的时候都会调用, 而__getattr__仅会在
__getattribute__未找到抛出异常的时候调用
#+END_VERSE
1. 这两个方法只对实例有效, 对类无效
2. 覆盖__getattribute__时注意避免无穷递归情况, 比如在里面使用self.__dict__查找属
   性, 这个操作本身也会触发自身的调用, 会导致无穷递归, 最好使用super委托父类查找
3. 如果__getattr__不抛出异常, 那么一定要显式的返回一个值, 不要返回None
4. 覆盖了__getattribute__后, 性能会有所损耗
5. 当property, 和这两个接口同时存在时, 优先__getattribute__, 然后property如果任何
   一个抛出了AttributeError则调用__getattr__

* 使用更为安全的Property
#+BEGIN_VERSE
property是实现属性管理的内建数据类型, 提供了高级的属性控制方式
#+END_VERSE
1. 代码更简洁, 可读性更强
2. 更好的管理属性的访问
3. 代码的可维护性更好
4. 控制属性访问权下, 提高数据安全性
5. 示例:
   #+begin_src python
     class Test(object):
         def __init__(self):
             self._x = 1

         @property
         def x(self):
             """return x"""  # 接口文档会作为属性的文档
             return self._x

         #@x.setter  # 如果不实现这个接口, 那么x就是只读的
         #def x(self, val):
         #    self._x = val

         #@x.deleter # 如果不实现这个接口, 那么x无法删除
         #def x(self):
         #    del self._x

     a = Test()
     print('x is {}'.format(a.x))
     try:
         del a.x
         a.x = 3
     except AttributeError as e:
         print(e)
   #+end_src

   #+RESULTS:
   : x is 1
   : can't delete attribute
   
* 掌握metaclass
#+BEGIN_VERSE
"元类是类的模板, 正如类是实例的模板"
#+END_VERSE
1. 当你在思考是否需要使用元类的时候, 那你就不需要它
2. 默认所有的新式类都用type作为元类, 如果父类设置了元类, 那么子类也会使用父类的元
   类
3. 元类中的方法可以作为类方法使用, 但是实例无法使用
4. 如果两个父类用两个不同的元类, 那么多重继承需要严格限制, 如果一定要多重继承, 可
   以新建一个元类C来继承两个父类的元类, 子类使用这个新的元类C作为元类
5. 示例:
   #+begin_src python
     class TestMeta(type):
         def __new__(cls, name, bases, attr):
             print(name, bases, attr)
             return type.__new__(cls, name, bases, attr)

         def Hello(cls):
             print('{} hello'.format(cls.__name__))

     # 使用元类的两种方式
     class A(object):
         __metaclass__ = TestMeta
     B = TestMeta('B', (object,), {'__module__': '__main__', '__metaclass__': TestMeta})

     A.Hello()
   #+end_src

   #+RESULTS:
   : ('A', (<type 'object'>,), {'__module__': '__main__', '__metaclass__': <class '__main__.TestMeta'>})
   : ('B', (<type 'object'>,), {'__module__': '__main__', '__metaclass__': <class '__main__.TestMeta'>})
   : A hello

* 熟悉python对象协议
#+BEGIN_VERSE
python是一门动态语言, 内置了大量的鸭子类型, 只要对象实现了某种协议, 那么这个对象
就支持特定的操作. 比如实现了__len__协议就可以查看容器的数量, 实现了__equal__就可
以比较引用是否相同等等
#+END_VERSE
1. 协议类型:
   - 类型转换协议, __repr__, __int__等等
   - 比较协议, __eq__, __lt__等等
   - 数值运算协议, __add__, __sub__等等
   - 位运算协议, __lshift__, __rshift__等等
   - 运算赋值协议, __iadd__, __isub__等等
   - 一元运算协议, __pos__, __neg__等等
   - 容器协议, __len__, __getitem__等等
   - 可调用对象协议, __call__
   - 属性交互和描述符协议, __enter__, __setattr__等等
   - 哈希协议, __hash__
2. 有很多运算协议前面会有一个r前缀, 这个代表反运算, 比如a+1调用a的__add__,
   那么1+a调用的就是a的__radd__
3. 不要滥用对象协议, 只有你实现的对象真的符合协议的要求才应该实现协议, 比如如果
   你的对象不是一个容器, 那你就不应该实现__len__

* 利用操作符重载实现中缀语法
#+BEGIN_VERSE
中缀语法在很多时候比前缀语法要更加清晰, pipe库通过重载|实现了中缀语法
#+END_VERSE
- 示例:
  #+begin_src python :results value
    import pipe
    # 计算5-10奇数平方之积
    arr = range(20)
    return reduce(lambda a, b: a*b,
                  arr | pipe.take_while(lambda x: x<10)
                  | pipe.skip_while(lambda x: x<5)
                  | pipe.where(lambda x: x&1)
                  | pipe.select(lambda x: x**2),
                  1)
  #+end_src

  #+RESULTS:
  : 99225
  
* 熟悉python的迭代器协议
#+BEGIN_VERSE
实现了__iter__和next接口, 或者仅实现了__getitem__的容器可以使用迭代器来访问元素
#+END_VERSE
1. __iter__方法需要返回一个迭代器, 迭代器自身的__iter__应返回自身
2. next()接口需要返回当前元素, 并指向下一个位置, 当无元素抛出StopIteration异常
3. 实现了迭代器可以惰性求值(比如生成器)
4. itertools库中提供了大量用于迭代的工具函数
5. 示例:
  #+begin_src python
    class MyIter(object):
        def __init__(self):
            self.list = [i for i in range(10)]

        def __getitem__(self, idx):
            return self.list[idx]

    print('getitem')
    it = MyIter()
    for i in it:
        print i,

    class MyIter(object):
        def __init__(self):
            self.list = [i for i in range(10)]
            self.idx = 0

        def __iter__(self):
            # for i in self.list:
            #     yield i
            return self

        def next(self):
            self.idx += 1
            if self.idx > len(self.list):
                raise StopIteration
            else:
                return self.list[self.idx-1]

    print('\niter')
    it = MyIter()
    for i in it:
        print i,
  #+end_src

#+RESULTS:
: getitem
: 0 1 2 3 4 5 6 7 8 9 
: iter
: 0 1 2 3 4 5 6 7 8 9

* 熟悉python生成器
#+BEGIN_VERSE
python的yield关键字会使得函数变为生成器函数, 调用函数返回一个生成器对象, 这个生成
器实现了迭代器协议, 可以生成一个序列
#+END_VERSE
- 示例:
  #+begin_src python
    def average():
        sum = 0
        num = 0
        while True:
          try:
              # yield表达式前后分为两部分, 第一次next或者send(None)称为预激
              # 会将控制流转给调用方, 并返回yield后面的值, 再次调用send会使yield
              # 表达式返回的值为send的值, 并将其赋给sum
              sum += yield 'average={}'.format(sum/num if num > 0 else 0)
              num += 1
          except Exception as e:
              print(e)

    generator = average()
    generator.send(None)
    print generator.send(3)
    print generator.send(13)
    print generator.throw(TypeError, 'TypeError')  # 可以主动向生成器内部发送异常
    print generator.send(5)
    generator.close()  # 主动关闭生成器
    try:
        generator.send(3)
    except StopIteration as e:
        print(type(e))
  #+end_src

  #+RESULTS:
  : average=3
  : average=8
  : TypeError
  : average=8
  : average=7
  : <type 'exceptions.StopIteration'>

* 基于生成器的协程和greenlet
#+BEGIN_VERSE
协程实际上是一种绿色的线程, 是由python实现的, 操作系统对此一无所知. 通过将控制权
主动让给主线程, 可以保证在任何时刻都只有一个协程在运行, 因此相比于线程无需作同步
控制, 但是丧失了程利用多核cpu的能力
#+END_VERSE
1. 通过yield关键字来将控制流转给调用者
2. python3通过yield from使得生成器的内外层可以直接交换数据, 对协程提供了全面的
   支持
3. 由于python2对协程支持有限, 因此可以使用greenlet库来支持协程

* 理解GIL的局限性
#+BEGIN_VERSE
python的GIL(全局解释器锁)可以保证任何情况下虚拟机中只有一个线程运行, 初衷是为了保
护虚拟机中共享对象访问的互斥性. 但是在多核情况下严重影响了python的性能表现
#+END_VERSE
1. GIL在单核多线程情况下基本没有影响
2. GIL在多核多线程IO密集的情况下, 性能还会有所下降
3. 可以通过multiprocessing来绕过GIL

* 对象的管理和垃圾回收
#+BEGIN_VERSE
python提供了垃圾回收机制, 程序员无需手动管理内存, 但是由于采用了引用计数法, 依然
存在出现内存泄露的情况
#+END_VERSE
1. python提供gc模块来处理循环引用, 但当对象存在析构方法时, 可能不会立即回收, 因为
   无法确定析构顺序
2. gc模块提供了debug模式, 可以方便程序员修复内存泄露错误
3. 示例:
   #+begin_src python
     import gc
     print('gc state = {}'.format(gc.isenabled()))
     class Leak(object):
         pass

     A = Leak()
     B = Leak()
     A.a = B
     B.a = A  # 循环引用
     A = None
     B = None
     collected = gc.collect()
     print('collect {} objects'.format(collected))
   #+end_src

   #+RESULTS:
   : gc state = True
   : collect 4 objects

* 从PyPI安装包
#+BEGIN_VERSE
当你需要一些独特的功能的时候, 很有可能不需要重复造轮子, 在PyPI上已经有大量的包提
供了各种各样的功能, 所以登陆PyPI去查看吧
#+END_VERSE
1. 可以通过安装setuptools之后, 使用easy_install命令安装PyPI上最新的包

* 使用pip和yolk安装, 管理包
#+BEGIN_VERSE
pip提供了对包版本控制的支持, 也支持对安装包的查看和删除等管理操作, 所以pip目前
是最流行的py包管理器
#+END_VERSE
1. pip install xx来安装包
2. pip list来查看安装的包
3. pip uninstall xxx来卸载包
4. yolk可以查看包实现了哪个插件协议

* 做paster创建包
#+BEGIN_VERSE
通过paster可以快速生成distutils需要的setup文件
#+END_VERSE
1. distutils标准库支持包的构建, 安装, 发布, PyPI的登记上传
2. 通过编写setup文件来作为distutils的入口
3. 通过pasterscript库可以根据模板快速生成setup文件, 减少工作量

* 理解单元测试概念
#+BEGIN_VERSE
单元测试由开发人员完成, 用来初步验证程序的正确性
#+END_VERSE
1. 单元测试有以下好处:
   - 减少了潜在的bug
   - 大大缩减软件修复成本
   - 为集成测试提供基础
2. 单元测试的步骤:
   1. 创建测试计划
   2. 编写测试用例准备测试数据
   3. 编写测试脚本
   4. 编写被测试代码, 代码完成之后执行测试脚本
   5. 修改代码缺陷, 直到代码可接受未知
3. 单元测试的基本原则:
   - 一致性 :: 每次执行测试的结果是一样的
   - 原子性 :: 每次测试的结果不是True就是是False
   - 单一职责 :: 测试应该基于情景, 而不是方法, 如果一个方法有多种行为, 那就应该有
     多个测试用例
   - 隔离性 :: 不能依赖于环境设置, 也不能依赖于其他用例的结果, 用例的输入输出应该
     是确定的
4. 使用单元测试框架unittest
   
* 为包编写单元测试
#+BEGIN_VERSE
使用自动测试框架unittest和nosetest可以方便的自动化执行单元测试
#+END_VERSE
- 示例:
  #+begin_src python
    import unittest

    class Arithmetic(object):
        def __init__(self, a, b):
            self.a = a
            self.b = b

        def sum(self):
            return self.a+self.b

        def diff(self):
            return self.a-self.b

        def product(self):
            return self.a*self.b

    class TestCase(unittest.TestCase):
        def setUp(self):
            """初始化环境"""
            print('run testcase')
            self.arith = Arithmetic(4, 4)

        def tearDown(self):
            """清理环境"""
            print('run over')
            del self.arith

        def test_add(self):
            self.assertEqual(self.arith.sum(), 4)

        def test_diff(self):
            self.assertEqual(self.arith.diff(), 0)

        def test_product(self):
            self.assertEqual(self.arith.product(), 16)

    # 运行测试用例
    unittest.main()
    #+end_src

  #+RESULTS:
  #+BEGIN_COMMENT
  run testcase
  run over
  run testcase
  run over
  run testcase
  run over
  ======================================================================
  FAIL: test_add (__main__.TestCase)
  ----------------------------------------------------------------------
  Traceback (most recent call last):
  File "<stdin>", line 30, in test_add
  AssertionError: 8 != 4

  ----------------------------------------------------------------------
  Ran 3 tests in 0.000s

  FAILED (failures=1)
  #+END_COMMENT

* 利用测试驱动开发提高代码的可测性
#+BEGIN_VERSE
测试驱动开发是敏捷开发中一个非常重要的理念, 强调在真正开始编码之前先行测试, 通过
迭代完成编码, 最终目的室编写干净可用的代码
#+END_VERSE
- 步骤:
  #+BEGIN_SRC plantuml
    @startuml
    start
    :编写可以运行测试的初版代码;
    repeat
        :编写测试用例;
        :运行测试;
    repeat while (测试失败?) is (no) not (yes)
    repeat
        :修改代码使其通过测试;
    repeat while (测试失败?) is (yes) not (no)
    :如果可能, 对代码进行重构;
    @enduml
  #+END_SRC

* 使用pylint检查代码风格
#+BEGIN_VERSE
如果团队使用pep编码风格, 那么可以使用pylint进行代码审查
#+END_VERSE
1. pylint的功能有:
   - 代码风格检查, 是否符合pep8
   - 代码错误检查
   - 发现重复以及设计不合理的代码
   - 和各种IDE集成
   - 能够基于python代码生成UML

* 进行高效的代码审查
#+BEGIN_VERSE
代码审查不是一件无聊, 形式主义的事. 它远远比你想象的要重要得多
#+END_VERSE
1. 代码审查会的主要目的是提高代码质量, 不允许讨论bug和如何修复
2. 代码审查过程不应该有kpi
3. 除非管理层真正参入到技术问题当中, 否则应避免加入审查
4. 将代码审查作为一个学习机会而不要理解为帮别人解决问题, 代码好可以让你学习, 代码
   不好可以让你以后避免一些糟糕的设计和实现
5. 评审可以借助一些工具
6. 评审的时间要控制到45-60min之内, 代码行数应当在200-400之间
7. 对事不对人, 不要人身攻击
8. 发现问题要及时记录

* 将包发布到PyPI
#+BEGIN_VERSE
通过python自带的distutils工具可以很方便地的将自己编写的库上传到PyPI上供他人使用
#+END_VERSE
1. 使用python setup.py register来注册账号
2. 使用python setup.py sdist upload上传库
3. 上传成功之后可以使用pip install进行安装

* 了解代码优化的基本原则
#+BEGIN_VERSE
代码优化代表着再不改变程序运行结果的前提下使代码运行的更快, 资源占用更少
#+END_VERSE
1. 优化代码前首先保证代码可以正确运行, 让正确的程序变快比让快的程序变正确要简单
2. 优化需要权衡质量, 时间, 成本, 代码本身需要权衡时间和空间, 而且要有重点的优化,
   毕竟80%的性能是由20%代码影响的
3. 需要明确优化的制标, 不能说优化的很快, 而要说优化到几秒之内反应, 并且优化要站在
   客户的角度上, 而不是开发的角度上
4. 优化代码也要兼顾可读性

* 借助性能优化工具
#+BEGIN_VERSE
比较常用的有Pypy和cPython
#+END_VERSE
1. 使用Pypy编译python代码时, 效率有显著的提高

* 利用cProfile定位性能瓶颈
#+BEGIN_VERSE
利用cProfile可以迅速定位程序运行的性能热点, 方便开发人员对代码进行优化
#+END_VERSE
- 示例:
  #+begin_src python
    print('==cProfile==')
    import cProfile
    def bar():
        pass
    def foo():
        s = '0'
        for i in range(20):
            bar()
            s += s
    import os
    path = os.path.join(os.environ['TMP'], 'profile.txt')
    cProfile.run('foo()', path)  # 使用run调用函数
    import pstats  # pstats提供了更加直观的报表分析
    p = pstats.Stats(path)
    p.sort_stats('ncalls').print_stats(3)

    print('==timeit==')
    import timeit  # 短小精悍的性能测量工具
    t = timeit.Timer('a.append(1)', 'a=[]')
    print (t.timeit(10000))  # 执行10000次需要的时间
  #+end_src

  #+RESULTS:
  #+begin_example
  ==cProfile==
  Thu Jul 22 20:47:18 2021    C:\Users\admin\AppData\Local\Temp\profile.txt

           24 function calls in 0.001 seconds

     Ordered by: call count
     List reduced from 5 to 3 due to restriction <3>

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
         20    0.000    0.000    0.000    0.000 <stdin>:4(bar)
          1    0.001    0.001    0.001    0.001 <stdin>:6(foo)
          1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}


  ==timeit==
  0.0004458
  #+end_example

* 使用memory_profiler和objgraph剖析内存使用
#+BEGIN_VERSE
使用这两个库可以方便追踪内存的变化以及内存泄露, 还可以显示对象之间的引用关系
#+END_VERSE
1. 使用memory_profiler的@profiler装饰器可以很方便的统计函数的内存使用情况
2. objgraph的showrefs可以以图片文件的形式显示对象内部的引用关系

* 努力降低算法的复杂度
#+BEGIN_VERSE
随着问题规模的扩大, 算法复杂度对于性能的影响将越来越明显, 所以努力降低算法的复杂
度可以有效提高性能
#+END_VERSE
1. 分析算法复杂度时几个注意点:
   - 每执行一条指令的时间时确定的
   - 每个语句的花费时间要根据语句的内容分析, 比如一个函数调用里面是一个O(n2)的循
     环, 那这个语句的复杂度就是O(n2)

* 掌握循环优化的基本技巧
#+BEGIN_VERSE
唯一原则, 减少循环内部的计算量
#+END_VERSE
1. 减少循环内部计算, 将内部不变的计算提到循环外
2. 显式循环转为隐式循环, 比如求等差数列和可以循环累加也可以直接公式计算
3. 循环内部尽量引用局部变量, 因为局部变量的查询速度更快, 因此当存在频繁使用的变量
   时, 将其转为局部变量会提高性能
4. 如果有嵌套循环, 尽量将内部循环计算向外层移动

* 使用生成器提高效率
#+BEGIN_VERSE
python的生成器采用惰性求值的迭代方式, 因此哪怕迭代无穷序列也仅会占用很少的内存
#+END_VERSE
1. 通过yield的语法来表明函数是生成器
2. next()方法获取生成器的下一个值
3. 生成器让代码更加优雅
4. 是协程的基石

* 使用不同的数据结构优化性能
#+BEGIN_VERSE
当解决性能的问题的时候, 除了考虑算法方面, 也需要考虑数据结构是否合适
#+END_VERSE
1. deque(双端队列)在元素数量频繁变化时, 性能优于list
2. bisect模块可以对有序列表进行二分搜索(lgn)和插入, 优于列表本身的搜素(n)
3. heapq模块可以将列表改为最大堆, 支持常用的堆操作, 比如n最大元素
4. 当你确定你的list中的元素都是一个类型的时候, 可以使用array模块优化内存

* 充分利用set的优势
#+BEGIN_VERSE
set在涉及到交并补等运算时效率远远高于list, 因此有这种需求的时候优先使用set
#+END_VERSE
1. set天生支持集合运算, 交并补操作比list更优雅
2. set在做集合操作时效率远远高于list, 即便规模为10也有3倍以上的效率, 规模越大
   差越明显

* 使用multiprocessing克服GIL的缺陷
#+BEGIN_VERSE
由于python的单个进程存在GIL, 所以并发任务可以使用multiprocessing来提高性能,
同时跳过GIL的限制
#+END_VERSE
1. 进程通信优先考虑Pipe和Queue
2. 尽量避免资源共享, 如果不可避免可以使用multiprocessing.Value等数据结构, 或
   使用服务器进程管理器multiprocessing.Manager来共享数据
   - Value等数据结构不是进程安全的
   - Manager只能传播被管理可变对象本身的改变, 如果可变对象本身包含的可变对象发生
     了改变则不会传播
3. 注意不同平台间进程的差异, 最好将共享的资源作为子进程的参数传入
   - Linux子进程会共享父进程中的资源
   - Windows父子进程相对独立
4. 不要使用terminate来终止进程
     
* 使用线程池提高效率
#+BEGIN_VERSE
当需要大量线程来完成任务, 但每个任务的持续时间很短时, 可以使用线程池来复用线程,
减少创建和销毁线程的开销
#+END_VERSE
1. 可以通过自己实现工作类和线程池管理器来实现一个线程池:
   - 工作类负责处理具体的任务, 一般继承自Threading
   - 线程池管理器管理线程队列和结果队列, 负责创建销毁线程对象和管理队列数据
2. python3.2的concurrent.futures.ThreadPoolExecutor提供了完备的线程池功能

* 使用C/C++模块扩展提高性能
#+BEGIN_VERSE
通过python提供的api, 可以很方便的将c/c++代码编译为python的模块, 可以将对性能要求
较高的部分使用c/c++编写
#+END_VERSE
1. 编写步骤:
   1. 使用c语言编写函数, 需要包含以下部分:
      - 导出函数 :: 带有PyObject* self 和 PyObject* args作为参数
      - 初始化函数 :: 以init开头, 使py解释器可以正确初始化
      - 方法列表 :: 提供给外部使用的接口列表, 每个元素是一个结构体:
        #+begin_src c
          struct PyMethodDef {
            char* ml_name;  // 方法名
            PyCFunction ml_meth;  // 导出函数
            int ml_flags;  // 参数传递方法
            char* ml_doc;  // 方法描述
          }
        #+end_src
   2. 编写setup脚本供distutils模块使用
   3. 使用python setup.py build进行编译
   4. 将生成的so文件复制到python的site_packages目录下, 即可import模块
      
* 使用Cython编写扩展模块
#+BEGIN_VERSE
使用Cython编写代码处理性能瓶颈, 这个模块根据类python代码生成c代码
#+END_VERSE
1. 使用pip install -U cython
2. 代码的编写除了类型声明以外基本和Python一致
3. 使用pyximport导入改名为.pyx结尾的原py文件, 可以无需显式编译
4. cython支持对c函数的调用
